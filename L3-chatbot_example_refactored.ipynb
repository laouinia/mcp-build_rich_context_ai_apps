{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad068e5f",
   "metadata": {},
   "source": [
    "# Lesson 3: Chatbot Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f0b0755",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Chatbot Example MCP.'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# Copyright 2025 LA (c)\n",
    "\"\"\"Chatbot Example MCP.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ccaa7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections.abc import Callable\n",
    "from pathlib import Path\n",
    "from typing import Any, Literal, Self, cast\n",
    "\n",
    "import anthropic\n",
    "import arxiv  # pyright: ignore[reportMissingTypeStubs]\n",
    "import pydantic\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5aa7f646",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.60.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anthropic.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b02667a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Constants\n",
    "PAPER_DIR = Path(\"papers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c522b28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Pydantic Models\n",
    "\n",
    "\n",
    "class SearchPapersArgs(pydantic.BaseModel):\n",
    "    \"\"\"Defines the arguments required for the 'search_papers' tool.\n",
    "\n",
    "    This model validates the input for searching papers, ensuring that a\n",
    "    topic is provided and the number of results is a valid integer.\n",
    "\n",
    "    Attributes:\n",
    "        topic: The topic to search for on arXiv.\n",
    "        max_results: The maximum number of papers to retrieve.\n",
    "    \"\"\"\n",
    "\n",
    "    topic: str\n",
    "    max_results: int = 5\n",
    "\n",
    "\n",
    "class ExtractInfoArgs(pydantic.BaseModel):\n",
    "    \"\"\"Defines the argument required for the 'extract_info' too.\n",
    "\n",
    "    Attributes:\n",
    "        paper_id (str): The ID of the paper to look for.\n",
    "    \"\"\"\n",
    "\n",
    "    paper_id: str\n",
    "\n",
    "\n",
    "class Tool(pydantic.BaseModel):\n",
    "    \"\"\"A model for defining a tool for the Anthropic API.\n",
    "\n",
    "    Attributes:\n",
    "        name: The name of the tool.\n",
    "        description: A short description of what the tool does.\n",
    "        input_schema: The JSON schema defining the tool's input parameters.\n",
    "    \"\"\"\n",
    "\n",
    "    name: str\n",
    "    description: str\n",
    "    input_schema: dict[str, Any]\n",
    "\n",
    "    @classmethod\n",
    "    def from_function(\n",
    "        cls,\n",
    "        func: Callable[..., Any],\n",
    "        arg_model: type[pydantic.BaseModel],\n",
    "    ) -> Self:\n",
    "        \"\"\"Creates a Tool instance from a function and a Pydantic model.\n",
    "\n",
    "        This method inspects a function and its corresponding argument model\n",
    "        to build a complete and validated tool definition.\n",
    "\n",
    "        Args:\n",
    "            func: The function to be converted into a tool.\n",
    "            arg_model: The Pydantic model that defines the function's arguments.\n",
    "\n",
    "        Returns:\n",
    "            An instance of the Tool class, configured with the function's\n",
    "            metadata and argument schema.\n",
    "        \"\"\"\n",
    "        description = \"\"\n",
    "\n",
    "        # Checks is docstring exists\n",
    "        if func.__doc__:\n",
    "            description = next((s for s in func.__doc__.splitlines() if s.strip()), \"\")\n",
    "\n",
    "        return cls(\n",
    "            name=func.__name__,\n",
    "            description=description,\n",
    "            input_schema=arg_model.model_json_schema(),\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26ea50b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type Aliases\n",
    "ToolArgs = SearchPapersArgs | ExtractInfoArgs\n",
    "ToolName = Literal[\"search_papers\", \"extract_info\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "206fb570",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pydantic.validate_call\n",
    "def search_papers(topic: str, max_results: int = 5) -> list[str]:\n",
    "    \"\"\"Search for papers on arXiv based on topic and store their informations.\n",
    "\n",
    "    Args:\n",
    "        topic (str): The topic of the search for\n",
    "        max_results (int, optional): Maximum number of result to retrieve. Defaults to 5.\n",
    "\n",
    "    Returns:\n",
    "        list[str]: List of paper IDs found in the search.\n",
    "    \"\"\"\n",
    "    # User arxiv to find the papers\n",
    "    client = arxiv.Client()\n",
    "\n",
    "    # Search for the most relevant articles matching the queried topic\n",
    "    search = arxiv.Search(\n",
    "        query=topic,\n",
    "        max_results=max_results,\n",
    "        sort_by=arxiv.SortCriterion.Relevance,\n",
    "    )\n",
    "\n",
    "    papers = client.results(search)\n",
    "\n",
    "    # Create directory for this topic\n",
    "    path: Path = Path(PAPER_DIR) / topic.lower().replace(\" \", \"_\")\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    file_path: Path = path / \"papers_info.json\"\n",
    "\n",
    "    try:\n",
    "        with file_path.open(mode=\"r\", encoding=\"utf-8\") as json_file:\n",
    "            papers_info = json.load(fp=json_file)\n",
    "    except (FileNotFoundError, json.JSONDecodeError):\n",
    "        papers_info = {}\n",
    "\n",
    "    # Process each paper and add to papers_info\n",
    "    paper_ids: list[str] = []\n",
    "    for paper in papers:\n",
    "        paper_ids.append(paper.get_short_id())\n",
    "        paper_info = {\n",
    "            \"title\": paper.title,\n",
    "            \"authors\": [author.name for author in paper.authors],\n",
    "            \"summary\": paper.summary,\n",
    "            \"pdf_url\": paper.pdf_url,\n",
    "            \"published\": str(paper.published.date()),\n",
    "        }\n",
    "\n",
    "        papers_info[paper.get_short_id()] = paper_info\n",
    "\n",
    "    # Save updated papers_info to json file\n",
    "    with file_path.open(mode=\"w\", encoding=\"utf-8\") as json_file:\n",
    "        json.dump(obj=papers_info, fp=json_file, indent=2)\n",
    "\n",
    "    print(f\"Results are saved in: {file_path}\")\n",
    "\n",
    "    return paper_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76527126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are saved in: papers\\computer\\papers_info.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['1310.7911v2',\n",
       " 'math/9711204v1',\n",
       " '2208.00733v1',\n",
       " '2504.07020v1',\n",
       " '2403.03925v1']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_papers(topic=\"computer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8e72fd",
   "metadata": {},
   "source": [
    "## Extract Info\n",
    "\n",
    "The second tool looks for information about a specific paper across all topic directories inside the papers directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "096e3233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refactor using a guard clause\n",
    "\n",
    "\n",
    "@pydantic.validate_call\n",
    "def extract_info(paper_id: str) -> str:\n",
    "    \"\"\"Search and retrieve information about a specific paper.\n",
    "\n",
    "    The Function scans all subdirectories within the main paper directory\n",
    "    for \"papers_info.json\" file and searches the file for the specific paper\n",
    "\n",
    "    Args:\n",
    "        paper_id (str): ID of paper to find.\n",
    "\n",
    "    Returns:\n",
    "        str: JSON-formatted string of the paper's information if found.\n",
    "             Otherwise a message that the paper was not found.\n",
    "    \"\"\"\n",
    "    base_dir = Path(PAPER_DIR)\n",
    "\n",
    "    # Use glob to find all papers_info.json files in subdirectories\n",
    "    for file_path in base_dir.glob(\"*/papers_info.json\"):\n",
    "        try:\n",
    "            # Use the Path Object's read_text method\n",
    "            papers_info = json.loads(file_path.read_text(encoding=\"utf-8\"))\n",
    "\n",
    "            if paper_id in papers_info:\n",
    "                # Return the specific paper's info, nicely formatted\n",
    "                return json.dumps(papers_info[paper_id], indent=2)\n",
    "\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error decoding JSON from {file_path}: {e}\")\n",
    "\n",
    "    return f\"There's no saved information related to paper {paper_id}.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9fec8fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"title\": \"Compact manifolds with computable boundaries\",\\n  \"authors\": [\\n    \"Zvonko Iljazovic\"\\n  ],\\n  \"summary\": \"We investigate conditions under which a co-computably enumerable closed set\\\\nin a computable metric space is computable and prove that in each locally\\\\ncomputable computable metric space each co-computably enumerable compact\\\\nmanifold with computable boundary is computable. In fact, we examine the notion\\\\nof a semi-computable compact set and we prove a more general result: in any\\\\ncomputable metric space each semi-computable compact manifold with computable\\\\nboundary is computable. In particular, each semi-computable compact\\\\n(boundaryless) manifold is computable.\",\\n  \"pdf_url\": \"http://arxiv.org/pdf/1310.7911v2\",\\n  \"published\": \"2013-10-29\"\\n}'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_info(paper_id=\"1310.7911v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854779a9",
   "metadata": {},
   "source": [
    "## Tools Schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46d87ee",
   "metadata": {},
   "source": [
    "Schema of each tool which you will provide to the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6adcdd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"name\": \"search_papers\",\n",
    "        \"description\": \"Search for papers on arXiv based on a topic and store their information.\",\n",
    "        \"input_schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"topic\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The topic to search for\",\n",
    "                },\n",
    "                \"max_results\": {\n",
    "                    \"type\": \"integer\",\n",
    "                    \"description\": \"Maximum number of results to retrieve\",\n",
    "                    \"default\": 5,\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"topic\"],\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"extract_info\",\n",
    "        \"description\": \"Search for information about a specific paper across all topic directories.\",\n",
    "        \"input_schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"paper_id\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The ID of the paper to look for\",\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"paper_id\"],\n",
    "        },\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5f71e2",
   "metadata": {},
   "source": [
    "## Tool Mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32bea270",
   "metadata": {},
   "source": [
    "This code handles tool mapping and execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d4ad698",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_tool_function = {\n",
    "    \"search_papers\": search_papers,\n",
    "    \"extract_info\": extract_info,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0bbdf6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @pydantic.validate_call\n",
    "def execute_tool(tool_name: ToolName, tool_args: ToolArgs) -> str:\n",
    "    \"\"\"Selects and executes a tool with validated arguments.\n",
    "\n",
    "    This function acts as a dispatcher. It uses Pydantic to validate the tool\n",
    "    name and its corresponding arguments, then calls the appropriate\n",
    "    tool function and normalizes the output into a string.\n",
    "\n",
    "    Args:\n",
    "        tool_name: The name of the tool to execute.\n",
    "        tool_args: A Pydantic model containing the validated\n",
    "            arguments for the specified tool.\n",
    "\n",
    "    Returns:\n",
    "        A formatted string representation of the tool's result.\n",
    "    \"\"\"\n",
    "    # Look up the function to call (search_papers or extract_info)\n",
    "    func_to_call = mapping_tool_function[tool_name]\n",
    "\n",
    "    # Convert the Pydantic model back to a dict and call the function\n",
    "    # result = mapping_tool_function[tool_name](**tool_args)  # noqa: ERA001\n",
    "    result = func_to_call(**tool_args.model_dump())\n",
    "\n",
    "    if isinstance(result, list):\n",
    "        result = \", \".join(result)\n",
    "\n",
    "    elif isinstance(result, dict):\n",
    "        # Convert dictionaries to formatted JSON strings\n",
    "        result = json.dumps(result, indent=2)\n",
    "\n",
    "    else:\n",
    "        # For any other type, convert using str()\n",
    "        result = str(result)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9494fd9",
   "metadata": {},
   "source": [
    "## ChatBot Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431a3e33",
   "metadata": {},
   "source": [
    "The chatbot handles the user's queries one by one, but it does not persist memory across the queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ac30225",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "client = anthropic.Anthropic()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93dba95d",
   "metadata": {},
   "source": [
    "### Query Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47bb6364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatically generate the correctly typed tools list\n",
    "tools = [\n",
    "    Tool.from_function(search_papers, SearchPapersArgs),\n",
    "    Tool.from_function(extract_info, ExtractInfoArgs),\n",
    "]\n",
    "\n",
    "# Convert the list of Tool objects to a list of dicts for the API\n",
    "tools_for_api: list[anthropic.types.ToolParam] = [\n",
    "    cast(\"anthropic.types.ToolParam\", tool.model_dump()) for tool in tools\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "118282e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_query(query: str) -> None:\n",
    "    \"\"\"Sends a query to the model and handles the tool use conversation.\n",
    "\n",
    "    Args:\n",
    "        query: The user's input string.\n",
    "    \"\"\"\n",
    "    messages: list[anthropic.types.MessageParam] = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": query,\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    while True:\n",
    "        response = client.messages.create(\n",
    "            max_tokens=2024,\n",
    "            model=\"claude-3-sonnet-20240229\",\n",
    "            tools=tools_for_api,\n",
    "            messages=messages,\n",
    "        )\n",
    "\n",
    "        messages.append({\"role\": response.role, \"content\": response.content})\n",
    "\n",
    "        # If the model's response does not require a tool, break the loop.\n",
    "        if response.stop_reason != \"tool_use\":\n",
    "            break\n",
    "\n",
    "        # If the model requires a tool, prepare the results.\n",
    "        tool_results: list[anthropic.types.ToolResultBlockParam] = []\n",
    "        for content_block in response.content:\n",
    "            if content_block.type == \"tool_use\":\n",
    "                tool_name = content_block.name\n",
    "                tool_args_dict = content_block.input\n",
    "                tool_id = content_block.id\n",
    "\n",
    "                print(f\"Calling tool {tool_name} with args {tool_args_dict}\")\n",
    "\n",
    "                # Validate the arguments against the correct Pydantic model\n",
    "                if tool_name == \"search_papers\":\n",
    "                    validated_args = SearchPapersArgs.model_validate(tool_args_dict)\n",
    "                    result = execute_tool(tool_name=tool_name, tool_args=validated_args)\n",
    "                elif tool_name == \"extract_info\":\n",
    "                    validated_args = ExtractInfoArgs.model_validate(tool_args_dict)\n",
    "                    result = execute_tool(tool_name=tool_name, tool_args=validated_args)\n",
    "                else:\n",
    "                    result = f\"Error: Unknown tool {tool_name}.\"\n",
    "\n",
    "                tool_results.append({\n",
    "                    \"type\": \"tool_result\",\n",
    "                    \"tool_use_id\": tool_id,\n",
    "                    \"content\": result,\n",
    "                })\n",
    "\n",
    "        # Add the tool results to the conversation history for the next turn\n",
    "        messages.append({\"role\": \"user\", \"content\": tool_results})\n",
    "\n",
    "    # Print the final text response from the assistant\n",
    "    for content in response.content:\n",
    "        if content.type == \"text\":\n",
    "            print(content.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0a3e4a",
   "metadata": {},
   "source": [
    "## Chat Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5f0a95aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_loop() -> None:\n",
    "    \"\"\"Initiates a chat loop for interacting with the user.\"\"\"\n",
    "    print(\"Type your query or 'quit' to exit.\")\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            query = input(\"\\nQuery: \").strip()\n",
    "\n",
    "            if query.lower() == \"quit\":\n",
    "                break\n",
    "\n",
    "            process_query(query=query)\n",
    "            print(\"\\n\")\n",
    "\n",
    "        # 1. Expected error first\n",
    "        except pydantic.ValidationError as e:\n",
    "            print(f\"\\nValidation Error: The model returned invalid arguments. \\n{e}\")\n",
    "\n",
    "        # 2. Exit Exception\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\nExiting chat loop.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mcp-build_rich_context_ai_apps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
